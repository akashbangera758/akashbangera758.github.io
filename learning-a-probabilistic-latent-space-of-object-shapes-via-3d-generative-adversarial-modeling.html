<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1">

<title>Learning a Probabilistic Latent Space of Object Shapes via 3D Generative Adversarial Modeling</title>
<meta name="description" content="Link to the paper">

<link rel="stylesheet" href="/css/main.css">
<link rel="canonical" href="http://akashbangera758.github.io/learning-a-probabilistic-latent-space-of-object-shapes-via-3d-generative-adversarial-modeling">

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-117489514-1', 'auto');
  ga('send', 'pageview');
</script>


</head>
<body>
  <header class="site-header">
  <div class="container">
    <input type="checkbox" id="toggleNavbar">
    <h1 class="logo"><a href="/">Akash <span>Bangera</span></a></h1>
    <label for="toggleNavbar" role="button" class="toggle-navbar-button">
      <i class="icon icon-menu"></i>
      <i class="icon icon-cross"></i>
    </label>
    <nav class="navbar">
      <ul>
        <li><a href="/" title="Home">Home</a></li>
        
          <li><a href="/about" title="About">About</a></li>
        
          <li><a href="/blog" title="Blog">Blog</a></li>
        
        <li><a href="https://drive.google.com/open?id=1s4X5CEzlL0tkFfFJBgHri_xyj5y_cjEq" title="Resume" target="_blank">Resume</a></li>
      </ul>
    </nav>
  </div>
</header>


<main class="main-container">
  <div class="container">
    <article role="article" class="post">

  <div class="card">
    <header class="post-header">
      <h1 class="post-title">Learning a Probabilistic Latent Space of Object Shapes via 3D Generative Adversarial Modeling</h1>
      <em class="post-meta">
        <time>Oct 14, 2018</time>
      </em>
    </header>

    <div class="post-content">
      
      <p><a href="http://3dgan.csail.mit.edu/papers/3dgan_nips.pdf" target="_blank">Link to the paper</a></p>

<h2>Contribution</h2>
<ul>
    <li>This paper introduces a new framework called 3DGAN, which generates 3D objects from a probabilistic space using volumetric convolutions and GANs.</li>
</ul>

<h2>Background</h2>
<ul>
    <li><strong>Generative Adversarial Nets (GAN)</strong>: <a href="https://akashbangera758.github.io/blog/2018/generative-adversarial-nets/" target="_blank">Refer here</a></li>
    <li><strong>Variational Autoencoder</strong>: An autoencoder network is actually a pair of two connected networks, an encoder and a decoder. An encoder network takes in an input, and converts it into a smaller, dense representation, which the decoder network can use to convert it back to the original input.</li>
    <li><strong>Volumetric Convolutions</strong>: Convolution layers for 3D input.</li>
</ul>

<h2>Description</h2>
<ul>
    <li>3D object understanding and generation is an important problem in the graphics and vision community.</li>
    <li>With the help of adversarial training, the generator encapsulates the object structure implicitly and then synthesizes high quality 3D objects.</li>
    <li>The generator establishes mapping from low dimensional probability space to a space of 3D objects, so that thereâ€™s no need of reference models or CAD models for generating 3D objects.</li>
    <li>This network, when combined with a variational autoencoder can directly reconstruct a 3D object from a 2D image.</li>
    <li>The discriminator provides a powerful 3D shape descriptor which, learned without supervision, has wide applications in 3D object recognition.</li>
</ul>

<h2>Methodology</h2>
<ul>
    <li>3D-GAN</li>
        <ul>
            <li type="circle">In 3D-GAN, a 200 dimensional latent vector <strong>z</strong>, randomly sampled from a probabilistic latent space, is converted to a 64 x 64 x 64 cube, by the generator <strong>G</strong>, representing an object <strong>G(z)</strong> in a 3D voxel space.</li>
            <li type="circle">The discriminator <strong>D</strong> takes in 3D object image <strong>x</strong> and gives as output a confidence value <strong>D(x)</strong> of whether the input is real or synthetic.</li>
            <li type="circle">Binary cross entropy is used as the loss function.</li>
            <li type="circle">The discriminator usually learns faster, and this makes it hard for the generator to improve, as all samples it generates are correctly identified as synthetic with high confidence.</li>
            <li type="circle">Therefore, to keep the training of both networks in pace, for each batch, the discriminator is updated only if its accuracy in the previous batch is less than 80%.</li>
        </ul>
    <li>3D-VAE-GAN</li>
        <ul>
            <li type="circle">The 3D-VAE-GAN consists of three components: an image encoder <strong>E</strong>, a generator <strong>G</strong>, and a discriminator <strong>D</strong>.</li>
            <li type="circle">The image encoder <strong>E</strong> takes 2D image as input and outputs the latent representation vector <strong>z</strong>.</li>
            <li type="circle">Further operations are similar to that of 3D-GAN.</li>
            <li type="circle">The loss function consists of three parts: an object reconstruction loss <strong>L<sub>recon</sub></strong>, a cross entropy loss <strong>L<sub>3D-GAN</sub></strong>, and a KL diversion loss <strong>L<sub>KL</sub></strong>.</li>
        </ul>
</ul>

<h2>Areas of Application</h2>
<ul>
    <li>3D Object Generation</li>
    <li>3D Object Classification</li>
    <li>Single Image 3D Reconstruction</li>
</ul>

<h2>Related Papers</h2>
<ul>
    <li><a href="https://arxiv.org/pdf/1711.06375.pdf" target="_blank">Shape Inpainting using 3D Generative Adversarial Network and Recurrent Convolutional Networks</a></li>
    <li><a href="https://arxiv.org/pdf/1707.09557.pdf" target="_blank">Improved Adversarial Systems for 3D Object Generation and Reconstruction</a></li>
    <li><a href="https://arxiv.org/pdf/1805.00328.pdf" target="_blank">3D-PhysNet: Learning the Intuitive Physics of Non-Rigid Object Deformations</a></li>
</ul>

<h2>Reference</h2>
<ul>
    <li><a href="https://towardsdatascience.com/intuitively-understanding-variational-autoencoders-1bfe67eb5daf" target="_blank">https://towardsdatascience.com/intuitively-understanding-variational-autoencoders-1bfe67eb5daf</a></li>
</ul>

    </div>

<!--    
-->
  </div>

</article>

  </div>
</main>

<footer class="site-footer">
  <div class="container">
    <ul class="social">
  <li><a href="https://github.com/akashbangera758" target="_blank"><i class="icon icon-github"></i></a></li>
  <li><a href="https://twitter.com/AkashB58" target="_blank"><i class="icon icon-twitter"></i></a></li>
  <li><a href="mailto:akashbangera758@gmail.com" target="_blank"><i class="icon icon-envelop"></i></a></li>
  <li><a href="https://linkedin.com/in/akashbangera758" target="_blank"><i class="icon icon-linkedin2"></i></a></li>
</ul>
  </div>
</footer>


</body>
</html>
