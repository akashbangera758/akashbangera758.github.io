<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1">

<title>Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks</title>
<meta name="description" content="Link to the paper">

<link rel="stylesheet" href="/css/main.css">
<link rel="canonical" href="http://akashbangera758.github.io/blog/2018/unsupervised-representation-learning-with-deep-convolutional-generative-adversarial-networks/">

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-117489514-1', 'auto');
  ga('send', 'pageview');
</script>


</head>
<body>
  <header class="site-header">
  <div class="container">
    <input type="checkbox" id="toggleNavbar">
    <h1 class="logo"><a href="/">Akash <span>Bangera</span></a></h1>
    <label for="toggleNavbar" role="button" class="toggle-navbar-button">
      <i class="icon icon-menu"></i>
      <i class="icon icon-cross"></i>
    </label>
    <nav class="navbar">
      <ul>
        <li><a href="/" title="Home">Home</a></li>
        
          <li><a href="/about" title="About">About</a></li>
        
          <li><a href="/blog" title="Blog">Blog</a></li>
        
        <li><a href="https://drive.google.com/open?id=1s4X5CEzlL0tkFfFJBgHri_xyj5y_cjEq" title="Resume" target="_blank">Resume</a></li>
      </ul>
    </nav>
  </div>
</header>


<main class="main-container">
  <div class="container">
    <article role="article" class="post">

  <div class="card">
    <header class="post-header">
      <h1 class="post-title">Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks</h1>
      <em class="post-meta">
        <time>Sep 2, 2018</time>
      </em>
    </header>

    <div class="post-content">
      
      <p><a href="https://arxiv.org/pdf/1511.06434.pdf" target="_blank">Link to the paper</a></p>

<h2>Contribution</h2>
<ul>
    <li>This paper introduces a version of GAN called Deep Convolutional Generative Adversarial Networks (DCGAN), which are stable to train in most settings.</li>
    <li>This paper also showed that the generators have vector arithmetic properties which allows for easy image manipulation.</li>
</ul>

<h2>Background</h2>
<ul>
    <li><strong>Generative Adversarial Nets (GAN)</strong>: <a href="https://akashbangera758.github.io/blog/2018/generative-adversarial-nets/" target="_blank">Refer here</a></li>
    <li><strong>Convolutional Neural Network</strong>: A convolutional neural network (CNN) is a class of deep, feed-forward artificial neural networks, most commonly applied to analyzing visual imagery.</li>
    <li><strong>Batch Normalization</strong>: Batch normalization helps stabilize learning by normalizing the inputs to each unit to have zero mean and unit variance.</li>
    <li><strong>ReLU Activation</strong>: ReLU (Rectified Linear Unit) is an activation function where f(x)=0 for x&lt;0 and f(x)=x for x&gt;=0.</li>
    <li><strong>LeakyReLU Activation</strong>: LeakyReLU is an activation function where f(x)=&alpha;x for x&lt;0 and f(x)=x for x&gt;=0. Here &alpha; is called leak and it helps increase the range of ReLU function.</li>
    <li><strong>Dropout</strong>: Dropout refers to dropping out units from layers in the neural network. This is done for reducing overfitting in neural networks.</li>
</ul>

<h2>Description</h2>
<ul>
    <li>Previous attempts to improve the performance of GANs to model images, using CNNs were unsuccessful.</li>
    <li>This paper tells us about the various layers and activations used by the authors in their network, for successfully modelling image distributions.</li>
    <li>The various settings and hyperparameters used by the authors, and their effects on the result, are also mentioned in the paper.</li>
</ul>

<h2>Methodology</h2>
<ul>
    <li>A uniform noise distribution <strong>z</strong> is fed into the first layer of generator, which can be a fully connected layer.</li>
    <li>This layer is used for matrix multiplication, and the result is reshaped into a 4-dimensional vector.</li>
    <li>For the discriminator, the last layer is flattened and then fed into a single sigmoid output.</li>
    <li>Pooling layers are replaced with strided convolutions for discriminator, and with fractional-strided convolutionals for generator.</li>
    <li>To prevent mode collapse, Batch Normalization has been used.</li>
    <li>Batch Normalization is not applied to the output layer of generator and the input layer of discriminator, as it may lead to sample oscillations and also model instability.</li>
    <li>The generator uses ReLU activations for all layers except the output, which uses Tanh.</li>
    <li>The discriminator uses LeakyReLU activations for all layers.</li>
    <li>Dropout was used to decrease the likelihood of memorization.</li>
</ul>

<h2>Experiments</h2>
<ul>
    <li>DCGANs were trained on three datasets, Large Scale Scene Understanding (LSUN), Imagenet-1K, and assembled Faces dataset.</li>
    <li>All images were scaled to the range of tanh activation function [-1, 1].</li>
    <li>Mini-batch Stochastic Gradient Descent (SGD) was used for training, with minibatch size of 128.</li>
    <li>Weights were initialized with zero-centered Normal distribution with standard deviation of 0.02.</li>
    <li>The slope of leak was set to 0.2 in LeakyReLU.</li>
    <li>Adam Optimizer was used for accelerating the training process.</li>
    <li>Learning rate was set to 0.0002 and the momentum term &beta; was set to 0.5 for stabilizing training.</li>
</ul>

<h2>Areas of Application</h2>
<ul>
    <li>Generation of higher resolution images</li>
    <li>Vector arithmetic can be performed on images in Z space to get results like <strong>man with glasses - normal man + normal woman = woman with glasses</strong>.</li>
    <li>The use of vector arithmetic could decrease the amount of data needed for modelling complex image distributions.</li>
</ul>

<h2>Related Papers</h2>
<ul>
    <li><a href="https://arxiv.org/pdf/1406.2661.pdf" target="_blank">Generative Adversarial Nets</a></li>
</ul>

    </div>

<!--    
-->
  </div>

</article>

  </div>
</main>

<footer class="site-footer">
  <div class="container">
    <ul class="social">
  <li><a href="https://github.com/akashbangera758" target="_blank"><i class="icon icon-github"></i></a></li>
  <li><a href="https://twitter.com/AkashB58" target="_blank"><i class="icon icon-twitter"></i></a></li>
  <li><a href="mailto:akashbangera758@gmail.com" target="_blank"><i class="icon icon-envelop"></i></a></li>
  <li><a href="https://linkedin.com/in/akashbangera758" target="_blank"><i class="icon icon-linkedin2"></i></a></li>
</ul>
  </div>
</footer>


</body>
</html>
